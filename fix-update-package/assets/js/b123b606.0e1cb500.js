"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[840],{3905:function(e,t,a){a.d(t,{Zo:function(){return u},kt:function(){return m}});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=r.createContext({}),d=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=d(e.components);return r.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),c=d(a),m=n,f=c["".concat(s,".").concat(m)]||c[m]||p[m]||o;return a?r.createElement(f,i(i({ref:t},u),{},{components:a})):r.createElement(f,i({ref:t},u))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,i=new Array(o);i[0]=c;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:n,i[1]=l;for(var d=2;d<o;d++)i[d]=a[d];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}c.displayName="MDXCreateElement"},9232:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return d},toc:function(){return u},default:function(){return c}});var r=a(7462),n=a(3366),o=(a(7294),a(3905)),i=["components"],l={sidebar_position:2},s="Data Filtering",d={unversionedId:"reference/data_preparation/data_filtering",id:"reference/data_preparation/data_filtering",isDocsHomePage:!1,title:"Data Filtering",description:"Data filtering refers to the process of choosing a smaller part of your dataset and using that subset for viewing or analysis.",source:"@site/docs/reference/data_preparation/data_filtering.md",sourceDirName:"reference/data_preparation",slug:"/reference/data_preparation/data_filtering",permalink:"/re-data/fix-update-package/docs/reference/data_preparation/data_filtering",editUrl:"https://github.com/re-data/re-data/edit/master/docs/docs/reference/data_preparation/data_filtering.md",version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Data Cleaning",permalink:"/re-data/fix-update-package/docs/reference/data_preparation/data_cleaning"},next:{title:"Data Normalization",permalink:"/re-data/fix-update-package/docs/reference/data_preparation/data_normalization"}},u=[{value:"filter_remove_duplicates",id:"filter_remove_duplicates",children:[]},{value:"filter_get_duplicates",id:"filter_get_duplicates",children:[]},{value:"Your ideas",id:"your-ideas",children:[]}],p={toc:u};function c(e){var t=e.components,a=(0,n.Z)(e,i);return(0,o.kt)("wrapper",(0,r.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"data-filtering"},"Data Filtering"),(0,o.kt)("p",null,"Data filtering refers to the process of choosing a smaller part of your dataset and using that subset for viewing or analysis."),(0,o.kt)("p",null,"Filtering may be used to:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Look at results for a particular period of time."),(0,o.kt)("li",{parentName:"ul"},'Exclude erroneous or "bad" observations from an analysis.'),(0,o.kt)("li",{parentName:"ul"},'Extract erroneous or "bad" observations from an analysis for manual ',(0,o.kt)("a",{parentName:"li",href:"https://www.gartner.com/en/documents/554646/best-practices-for-data-stewardship"},"(by data stewards)"),"/ ",(0,o.kt)("a",{parentName:"li",href:"https://www2.deloitte.com/nl/nl/pages/enterprise-technology-and-performance/articles/augmented-data-management-beyond-the-hype.html"},"augmented (AI)")," Data Quality Management.")),(0,o.kt)("p",null,"re_data provides the following macros for filtering data. Check out the list of currently available filters and let us know if you could use some different ones on ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"https://www.getre.io/slack"},"Slack \ud83d\ude0a"))," or ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"https://github.com/re-data/re-data/issues/new?assignees=&labels=&template=macro_request.md&title=%5BMACRO%5D"},"Github")),"."),(0,o.kt)("h3",{id:"filter_remove_duplicates"},(0,o.kt)("a",{parentName:"h3",href:"https://re-data.github.io/dbt-re-data/#!/macro/macro.re_data.filter_remove_duplicates"},"filter_remove_duplicates")),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Arguments:")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"relation: dbt model to perform the filtering on")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"unique_cols: List of columns that uniquely identify each row")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"sort_columns: Order in which we want to sort the partitioned rows. e.g. (created_at DESC, created_at ASC to choose the latest or earliest row based on the timestamp column"))),(0,o.kt)("p",null,"Return type: table with filtered rows"),(0,o.kt)("p",null,"This macro allows you to remove duplicate rows from a dbt model based on certain conditions."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"  id |  status      |   updated_at    |\n--------------------------------------+\n 1   |  pending     |    13:00:45     |\n 2   |  completed   |    13:05:23     |\n 1   |  completed   |    13:10:35     |\n 2   |  pending     |    13:04:49     |\n 3   |  completed   |    13:30:00     |\n\n => select id, status, updated_at from {{ re_data.filter_remove_duplicates(ref('duplicated'), ['id'], ['updated_at desc']) }} duplicates\n\n -- After filtering, the resulting rows are:\n\n  id |  status      |   updated_at    |\n--------------------------------------+\n 1   |  completed   |    13:10:35     |\n 2   |  completed   |    13:05:23     |\n 3   |  completed   |    13:30:00     |\n")),(0,o.kt)("h3",{id:"filter_get_duplicates"},(0,o.kt)("a",{parentName:"h3",href:"https://re-data.github.io/dbt-re-data/#!/macro/macro.re_data.filter_get_duplicates"},"filter_get_duplicates")),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Arguments:")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"relation: dbt base model to perform the filtering on")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"unique_cols: List of columns that uniquely identify each row")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"sort_columns: Order in which we want to sort the partitioned rows. e.g. (created_at DESC, created_at ASC to choose the latest or earliest row based on the timestamp column"))),(0,o.kt)("p",null,"Return type: table with duplicate rows"),(0,o.kt)("p",null,"along with the fields of the base model the macro returns duplication context in new fields:\nre_data_duplicates_count - total number of duplicates with the same current key set\nre_data_duplicate_row_number - number of current duplicate row inside the group of duplicates with the same current key set"),(0,o.kt)("p",null,"This macro allows you to get duplicate rows from a dbt model based on certain conditions."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"  id |  status      |   updated_at    |\n--------------------------------------+\n 1   |  pending     |    13:00:45     |\n 2   |  completed   |    13:05:23     |\n 1   |  completed   |    13:10:35     |\n 2   |  pending     |    13:04:49     |\n 3   |  completed   |    13:30:00     |\n\n => select id, status, updated_at,\n       re_data_duplicate_group_row_count, \n       re_data_duplicate_group_row_number\n    from {{ re_data.filter_get_duplicates( ref('duplicated') , ['id'], ['updated_at desc']) }}  duplicates\n\n -- After filtering, the resulting rows are:\n\n id | updated_at |  status   | re_data_duplicate_group_row_count | re_data_duplicate_group_row_number\n----+------------+-----------+-----------------------------------+------------------------------------\n  1 | 13:10:35   | completed |                                 2 |                                  1\n  1 | 13:00:45   | pending   |                                 2 |                                  2\n  2 | 13:05:23   | completed |                                 2 |                                  1\n  2 | 13:04:49   | pending   |                                 2 |                                  2\n")),(0,o.kt)("h2",{id:"your-ideas"},"Your ideas"),(0,o.kt)("p",null,"If you have other suggestions of filtering data which you would like to be supported\n",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"https://www.getre.io/slack"},"let us know on Slack! \ud83d\ude0a"))))}c.isMDXComponent=!0}}]);